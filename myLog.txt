
Building model...

Computing reachable states... 29 states
Reachable states exploration and model construction done in 0.293 secs.
Sorting reachable states list...

Computing reachable states... 43 states
Reachable states exploration and model construction done in 0.19 secs.
Sorting reachable states list...
Progress:

product construction took 0.273137 s

Time for model construction: 0.798 seconds.
//////////////////////////////////////////////////////////////////////////////
//                   STARTING COMPOSITIONAL MODEL CHECKING                  //
//////////////////////////////////////////////////////////////////////////////

Building Model ... 

Computing reachable states... 29 states
Reachable states exploration and model construction done in 0.208 secs.
Sorting reachable states list...

Computing reachable states... 43 states
Reachable states exploration and model construction done in 0.231 secs.
Sorting reachable states list...

Model checking : "q1": <<1>> ((((R{"c1_ru"}<=MAXRUA [ C ]=>R{"c2_ru"}<=MAXRUB [ C ]))))

Reducing multi-objective query to CNF: R{"c1_ru"}>MAXRUA [ C ]|R{"c2_ru"}<=MAXRUB [ C ]
expr: [[R{"c1_ru"}>MAXRUA [ C ], R{"c2_ru"}<=MAXRUB [ C ]]]

Warning: Strict inequalities ignored and turned into nonstrict inequalities:
	R{"c1_ru"}>MAXRUA [ C ]

/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1_ru"}>MAXRUA [ C ], R{"c2_ru"}<=MAXRUB [ C ]]]

initial state: 10
operation: Strategy generation
Strategy construction took 0.103544 s
Synthesis took 0.237098 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
29
// Initial state
InitState:
10
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
0 0 {0=1.0}
1 0 {0=1.0}
2 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
10 0 0 {0=1.0}
11 0 0 {0=1.0}
11 0 1 {0=1.0}
11 0 2 {0=1.0}
11 0 3 {0=1.0}
11 0 4 {0=1.0}
11 0 5 {0=1.0}
11 0 6 {0=1.0}
11 0 7 {0=1.0}
11 0 8 {0=1.0}
19 0 0 {0=1.0}
20 0 0 {0=1.0}
21 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 11 {0=1.0}
1 0 0 20 {0=1.0}
2 0 0 21 {0=1.0}
10 0 0 19 {0=1.0}
11 0 0 20 {0=1.0}
11 0 0 21 {0=1.0}
11 1 0 20 {0=1.0}
11 1 0 21 {0=1.0}
11 2 0 20 {0=1.0}
11 2 0 21 {0=1.0}
11 3 0 20 {0=1.0}
11 3 0 21 {0=1.0}
11 4 0 20 {0=1.0}
11 4 0 21 {0=1.0}
11 5 0 20 {0=1.0}
11 5 0 21 {0=1.0}
11 6 0 20 {0=1.0}
11 6 0 21 {0=1.0}
11 7 0 20 {0=1.0}
11 7 0 21 {0=1.0}
11 8 0 20 {0=1.0}
19 0 0 0 {0=1.0}
20 0 0 1 {0=1.0}
21 0 0 2 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

maximum D-iterations: 500
	D-iteration offset: 1
endstrategy


Number of states satisfying "q1": 29 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.34900000000000003 seconds.

Result: true (property satisfied in the initial state)

Model checking : "q2": <<1>> ((((R{"c1_rt"}<=MAXRTA [ C ]=>R{"c2_rt"}<=MAXRTB [ C ]))))

Reducing multi-objective query to CNF: R{"c1_rt"}>MAXRTA [ C ]|R{"c2_rt"}<=MAXRTB [ C ]
expr: [[R{"c1_rt"}>MAXRTA [ C ], R{"c2_rt"}<=MAXRTB [ C ]]]

Warning: Strict inequalities ignored and turned into nonstrict inequalities:
	R{"c1_rt"}>MAXRTA [ C ]

/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1_rt"}>MAXRTA [ C ], R{"c2_rt"}<=MAXRTB [ C ]]]

initial state: 17
operation: Strategy generation
Strategy construction took 0.014663 s
Synthesis took 0.075682 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
43
// Initial state
InitState:
17
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
0 0 {0=1.0}
1 0 {0=1.0}
2 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
17 0 0 {0=1.0}
18 0 0 {0=1.0}
18 0 1 {0=1.0}
26 0 0 {0=1.0}
27 0 0 {0=1.0}
28 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 18 {0=1.0}
1 0 0 27 {0=1.0}
2 0 0 28 {0=1.0}
17 0 0 26 {0=1.0}
18 0 0 27 {0=1.0}
18 1 0 27 {0=1.0}
18 1 0 28 {0=1.0}
26 0 0 0 {0=1.0}
27 0 0 1 {0=1.0}
28 0 0 2 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

maximum D-iterations: 500
	D-iteration offset: 1
endstrategy


Number of states satisfying "q2": 43 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.09000000000000001 seconds.

Result: true (property satisfied in the initial state)
//////////////////////////////////////////////////////////////////////////////
//                   COMPLETED COMPOSITIONAL MODEL CHECKING                 //
//////////////////////////////////////////////////////////////////////////////


Model checking completed in 0.916 secs.

Result: true

Reducing multi-objective query to CNF: R{"c1_ru"}<=MAXRUA [ C ]&R{"c2_ru"}<=MAXRUB [ C ]
expr: [[R{"c1_ru"}<=MAXRUA [ C ]], [R{"c2_ru"}<=MAXRUB [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1_ru"}<=MAXRUA [ C ]], [R{"c2_ru"}<=MAXRUB [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.088564 s
Synthesis took 0.954713 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
706
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {3=1.0}
3 0 {3=1.0}
25 0 {3=1.0}
39 0 {3=1.0}
134 0 {3=1.0}
135 0 {0=1.0}
136 0 {3=1.0}
137 0 {0=1.0}
510 0 {0=1.0}
511 0 {0=1.0}
512 0 {0=1.0}
513 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
1 0 1 {0=1.0}
2 0 3 {0=1.0}
3 0 3 {0=1.0}
7 0 0 {0=1.0}
15 0 0 {0=1.0}
15 0 1 {0=1.0}
25 0 3 {0=1.0}
39 0 3 {0=1.0}
40 0 0 {0=1.0}
40 0 1 {0=1.0}
41 0 0 {0=1.0}
41 0 1 {0=1.0}
85 0 0 {0=1.0}
85 0 1 {0=1.0}
134 0 3 {0=1.0}
135 0 0 {0=1.0}
136 0 3 {0=1.0}
137 0 0 {0=1.0}
251 0 0 {0=1.0}
251 0 1 {0=1.0}
252 0 0 {0=1.0}
253 0 0 {0=1.0}
510 0 0 {0=1.0}
511 0 0 {0=1.0}
512 0 0 {0=1.0}
513 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
1 1 0 3 {0=1.0}
2 3 0 7 {0=1.0}
3 3 0 15 {0=1.0}
7 0 0 25 {0=1.0}
15 0 0 39 {0=1.0}
15 1 0 40 {0=1.0}
15 1 0 41 {0=1.0}
25 3 0 85 {0=1.0}
39 3 0 85 {0=1.0}
40 0 0 134 {0=1.0}
40 1 0 135 {0=1.0}
41 0 0 136 {0=1.0}
41 1 0 137 {0=1.0}
85 0 0 251 {0=1.0}
85 1 0 252 {0=1.0}
85 1 0 253 {0=1.0}
134 3 0 252 {0=1.0}
135 0 0 40 {0=1.0}
136 3 0 253 {0=1.0}
137 0 0 41 {0=1.0}
251 0 0 510 {0=1.0}
251 1 0 511 {0=1.0}
252 0 0 512 {0=1.0}
253 0 0 513 {0=1.0}
510 0 0 251 {0=1.0}
511 0 0 251 {0=1.0}
512 0 0 252 {0=1.0}
513 0 0 253 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> ((R{"c1_ru"}<=MAXRUA [ C ]&R{"c2_ru"}<=MAXRUB [ C ])): 706 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.9870000000000001 seconds.

Result: true (property satisfied in the initial state)
