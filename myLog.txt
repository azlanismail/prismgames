
Building model...

Computing reachable states... 13 states
Reachable states exploration and model construction done in 0.179 secs.
Sorting reachable states list...

Computing reachable states... 3 states
Reachable states exploration and model construction done in 0.107 secs.
Sorting reachable states list...
product construction took 0.004757 s

Time for model construction: 0.374 seconds.

Reducing multi-objective query to CNF: R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]
expr: [[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.106785 s
Synthesis took 0.352287 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
13
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {0=1.0}
9 0 {0=1.0}
10 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
3 0 0 {0=1.0}
5 0 0 {0=1.0}
6 0 0 {0=1.0}
9 0 0 {0=1.0}
10 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
2 0 0 3 {0=1.0}
3 0 0 5 {0=1.0}
3 0 0 6 {0=1.0}
5 0 0 9 {0=1.0}
6 0 0 10 {0=1.0}
9 0 0 5 {0=1.0}
10 0 0 6 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> (((R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]))): 13 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.505 seconds.

Result: true (property satisfied in the initial state)

Building model...

Computing reachable states... 13 states
Reachable states exploration and model construction done in 0.232 secs.
Sorting reachable states list...

Computing reachable states... 3 states
Reachable states exploration and model construction done in 0.14600000000000002 secs.
Sorting reachable states list...
product construction took 0.001005 s

Time for model construction: 0.397 seconds.

Reducing multi-objective query to CNF: R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]
expr: [[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.023875 s
Synthesis took 0.062255 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
13
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {0=1.0}
9 0 {0=1.0}
10 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
3 0 0 {0=1.0}
5 0 0 {0=1.0}
6 0 0 {0=1.0}
9 0 0 {0=1.0}
10 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
2 0 0 3 {0=1.0}
3 0 0 5 {0=1.0}
3 0 0 6 {0=1.0}
5 0 0 9 {0=1.0}
6 0 0 10 {0=1.0}
9 0 0 5 {0=1.0}
10 0 0 6 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> (((R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]))): 13 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.07800000000000001 seconds.

Result: true (property satisfied in the initial state)

Building model...

Computing reachable states... 13 states
Reachable states exploration and model construction done in 0.2 secs.
Sorting reachable states list...

Computing reachable states... 3 states
Reachable states exploration and model construction done in 0.15200000000000002 secs.
Sorting reachable states list...
product construction took 0.008646 s

Time for model construction: 0.375 seconds.

Reducing multi-objective query to CNF: R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]
expr: [[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.023841 s
Synthesis took 0.062178 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
13
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {0=1.0}
9 0 {0=1.0}
10 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
3 0 0 {0=1.0}
5 0 0 {0=1.0}
6 0 0 {0=1.0}
9 0 0 {0=1.0}
10 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
2 0 0 3 {0=1.0}
3 0 0 5 {0=1.0}
3 0 0 6 {0=1.0}
5 0 0 9 {0=1.0}
6 0 0 10 {0=1.0}
9 0 0 5 {0=1.0}
10 0 0 6 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> (((R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]))): 13 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.07800000000000001 seconds.

Result: true (property satisfied in the initial state)

Building model...

Computing reachable states... 13 states
Reachable states exploration and model construction done in 0.163 secs.
Sorting reachable states list...

Computing reachable states... 3 states
Reachable states exploration and model construction done in 0.167 secs.
Sorting reachable states list...
product construction took 0.011468 s

Time for model construction: 0.35300000000000004 seconds.

Reducing multi-objective query to CNF: R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]
expr: [[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.028918 s
Synthesis took 0.065614 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
13
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {0=1.0}
9 0 {0=1.0}
10 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
3 0 0 {0=1.0}
5 0 0 {0=1.0}
6 0 0 {0=1.0}
9 0 0 {0=1.0}
10 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
2 0 0 3 {0=1.0}
3 0 0 5 {0=1.0}
3 0 0 6 {0=1.0}
5 0 0 9 {0=1.0}
6 0 0 10 {0=1.0}
9 0 0 5 {0=1.0}
10 0 0 6 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> (((R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]))): 13 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.07500000000000001 seconds.

Result: true (property satisfied in the initial state)

Building model...

Computing reachable states... 13 states
Reachable states exploration and model construction done in 0.14800000000000002 secs.
Sorting reachable states list...

Computing reachable states... 3 states
Reachable states exploration and model construction done in 0.139 secs.
Sorting reachable states list...
product construction took 0.000616 s

Time for model construction: 0.30900000000000005 seconds.

Reducing multi-objective query to CNF: R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]
expr: [[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]
/////////////////   NEW (DIRECT) MODEL CHECKING TASK     /////////////////////
Property:
	[[R{"c1max_rt"}<=MAXRT [ C ]], [R{"c1sum_ru"}<=MAXRU [ C ]], [R{"c2max_rt"}<=MAXRT [ C ]], [R{"c2sum_ru"}<=MAXRU [ C ]]]

initial state: 0
operation: Strategy generation
Strategy construction took 0.020214 s
Synthesis took 0.052580 s
strategy: $SU.strat-v0.1
// Stochastic Memory Update Strategy
start strategy
States:
13
// Initial state
InitState:
0
// initial distribution
Init:
{0=1.0}
// next state function
// note: only P1 states
Next:
// first index: current state
// second index: current corner
2 0 {0=1.0}
9 0 {0=1.0}
10 0 {0=1.0}
// memory update function: player states
MemUpdStates:
// first index: current state
// second index: current corner
// third index: next move
0 0 0 {0=1.0}
1 0 0 {0=1.0}
2 0 0 {0=1.0}
3 0 0 {0=1.0}
5 0 0 {0=1.0}
6 0 0 {0=1.0}
9 0 0 {0=1.0}
10 0 0 {0=1.0}
// memory update function: moves
MemUpdMoves:
// first index: current state
// second index: current move
// third index: curent corner (at move)
// fourth index: next state
0 0 0 1 {0=1.0}
1 0 0 2 {0=1.0}
2 0 0 3 {0=1.0}
3 0 0 5 {0=1.0}
3 0 0 6 {0=1.0}
5 0 0 9 {0=1.0}
6 0 0 10 {0=1.0}
9 0 0 5 {0=1.0}
10 0 0 6 {0=1.0}
Info:

maximum C-iterations: 500
	relative termination threshold: 0.010000
	bounding box: 

endstrategy


Number of states satisfying <<1>> (((R{"c1max_rt"}<=MAXRT [ C ]&R{"c1sum_ru"}<=MAXRU [ C ]&R{"c2max_rt"}<=MAXRT [ C ]&R{"c2sum_ru"}<=MAXRU [ C ]))): 13 (all in model)

Property satisfied in 1 of 1 initial states.

Time for model checking: 0.063 seconds.

Result: true (property satisfied in the initial state)
